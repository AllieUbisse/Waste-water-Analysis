{"cells":[{"cell_type":"markdown","source":["![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQ4EreGzBWX2DaX8Scl4aT-SasVzuzGD__isw&usqp=CAU) ![](https://d33wubrfki0l68.cloudfront.net/e7ed9fe4bafe46e275c807d63591f85f9ab246ba/e2d28/assets/images/tux.png)\n\n# Sanitary Sewer Overflows\n\n*getting started notebook* [data source 1](https://data.bloomington.in.gov/dataset/sanitary-sewer-overflows/resource/2e44981b-bb63-46b3-ba66-9b3b09786ec4) | [data source 2](https://data.world/city-of-bloomington/51fdd0d4-2fa2-4dd4-a877-8f683fb72f93)\n\n[Creative Commons Attribution license](http://opendefinition.org/licenses/cc-by/)\n\nAUTHOR: **ALLIE .S UBISSE**\n\n---\n\n**DESCRIPTION**<br>\nSanitary Sewer Overflows\n\n**OBJECTIVES**<br>\n- Checking if you understand the project as an indivisual\n- Generating Ideas on how we can achieve the main goal(s)\n- Simulate the main project\n- Learning Pyspark, Structured Streaming,  Data Cleaning, Data Quality checks, etc.\n\n**SUMMARY**<br>\n\nSanitary Sewer Overflows (SSO) are releases of untreated sewage into the environment. City of Bloomington Utilities Department records and maintains data for all SSO events that occur within Bloomington's wastewater collection and treatment system. Additionally, each event is reported to the Indiana Department of Environmental Management. Excel Worksheet labeled \"Sanitary Sewer Overflow Master\" is data recorded following each SSO event from 1996 forward.\nThis contains SSO incidents from 1996 forward, including overflow **dates**, **locations**, **estimated flow**, and any additional data we have about the individual event (i.e. **precipitation**, **blockage**, **power outage**, **snow melt**, etc).\n<br>\n\n**Data Dictionary**\n\n|Column\t    |   Type\t    |     Label |\tDescription |\n|:-----------|:---------------|:-----------:|---------------:|\n|Manhole    |\ttext\t\t|           |               |\n|Start_Date\t|    timestamp\t|\t n/a      |\n|End_Date    |\ttext\t\t|           |\n|Location\t|    text\t\t|           |\n|Event\t    |     text\t\t|           |     n/a\n|Rain\t    |    text\t\t|           |\n|Gallons     | \ttext\t\t|           |\n|Lat         |\tnumeric\t\t|           |\n|Long        | \tnumeric     |           |               |\n\n---\n\n## Tasks\n1. verify features(columns).\n2. verify data types.\n3. understand the meaning of missing data.\n4. verify data entries.\n5. explode/split compound feaures to simpler/atomic features.\n6. what assumptions can you draw from the data or what do you understand?\n7. create new aggrigate fetures from your assumptions validated using domain knowledge.\n8. visualize your assumption or relationships that might exist.\n9. So what might be the main problem behind the problem and how can this data help better the situation?\n10. Apply the thoughts from 9 and validate using domain knowledge or with stackholders.\n11. suppose the ideas are valid and we have a stream of data, implement a SPARK STRUCTURED STREAM **ETL**\n12. Build a DataBricks DashBoard using the streamed data/ static data.\n13. Can the dashboard answer business Questions? \n14. if #13 is No/not sure! what is irralevant and what can be improved?"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\nfrom pyspark.sql import types as T\n\n# start a spark session/ not necessary\nspark = SparkSession.builder.appName('Test').getOrCreate()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.Javascript object&gt;\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["# data path \nDATA_PATH='/FileStore/tables/sanitary_sewer_overflow_master_csv.csv'\n\n# load data to spark dataframe\nsewer_df = spark.read.csv(DATA_PATH, inferSchema=True, header=True)\n\n# view 1st 5 examples\nsewer_df.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+-------------------+----------+--------------------+-------------+----+-------+-----------+------------+----+----+----+----+----+----+----+----+----+\nManhole|         Start_Date|  End_Date|            Location|        Event|Rain|Gallons|        Lat|        Long| _c9|_c10|_c11|_c12|_c13|_c14|_c15|_c16|_c17|\n+-------+-------------------+----------+--------------------+-------------+----+-------+-----------+------------+----+----+----+----+----+----+----+----+----+\n   3430|1996-01-17 00:00:00|1996-01-17|        Gifford Road|Precipitation|null|   9000|39.15461147|-86.58559815|null|null|null|null|null|null|null|null|null|\n   1004|1996-01-17 00:00:00|1996-01-17|        Micro Motors|Precipitation|null| 378000|39.15424046|-86.53475475|null|null|null|null|null|null|null|null|null|\n   3607|1996-01-17 00:00:00|1996-01-17|  Sherwood Oaks Park|Precipitation|null|   6000|39.12983645|-86.51441395|null|null|null|null|null|null|null|null|null|\n   3138|1996-01-17 00:00:00|1996-01-17|Tapp Road Lift St...|Precipitation|null|  16000| 39.1366197|-86.56178514|null|null|null|null|null|null|null|null|null|\n   1004|1996-01-23 00:00:00|1996-01-23|        Micro Motors|Precipitation|null|  90000|39.15424046|-86.53475475|null|null|null|null|null|null|null|null|null|\n+-------+-------------------+----------+--------------------+-------------+----+-------+-----------+------------+----+----+----+----+----+----+----+----+----+\nonly showing top 5 rows\n\n&lt;IPython.core.display.Javascript object&gt;\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["# remove irrelevant features e.g _c*\nused_columns = [col for col in sewer_df.columns if not col.startswith('_c')]\nsewer_df = sewer_df.select(used_columns)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;IPython.core.display.Javascript object&gt;\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["# review 1st 5 rows\nsewer_df.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+-------------------+-------------------+--------------------+-------------+----+-------+-----------+------------+\nManhole|         Start_Date|           End_Date|            Location|        Event|Rain|Gallons|        Lat|        Long|\n+-------+-------------------+-------------------+--------------------+-------------+----+-------+-----------+------------+\n   3430|1996-01-17 00:00:00|1996-01-17 00:00:00|        Gifford Road|Precipitation|null|   9000|39.15461147|-86.58559815|\n   1004|1996-01-17 00:00:00|1996-01-17 00:00:00|        Micro Motors|Precipitation|null| 378000|39.15424046|-86.53475475|\n   3607|1996-01-17 00:00:00|1996-01-17 00:00:00|  Sherwood Oaks Park|Precipitation|null|   6000|39.12983645|-86.51441395|\n   3138|1996-01-17 00:00:00|1996-01-17 00:00:00|Tapp Road Lift St...|Precipitation|null|  16000| 39.1366197|-86.56178514|\n   1004|1996-01-23 00:00:00|1996-01-23 00:00:00|        Micro Motors|Precipitation|null|  90000|39.15424046|-86.53475475|\n+-------+-------------------+-------------------+--------------------+-------------+----+-------+-----------+------------+\nonly showing top 5 rows\n\n&lt;IPython.core.display.Javascript object&gt;\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# let's verify schema with the data dctionary & what we saw from the previous cell\nsewer_df.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Manhole: string (nullable = true)\n-- Start_Date: timestamp (nullable = true)\n-- End_Date: string (nullable = true)\n-- Location: string (nullable = true)\n-- Event: string (nullable = true)\n-- Rain: string (nullable = true)\n-- Gallons: string (nullable = true)\n-- Lat: double (nullable = true)\n-- Long: double (nullable = true)\n\n&lt;IPython.core.display.Javascript object&gt;\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# let's cast Manhole-->int, End_Date-->timestamp and Gallons-->integer/long\nsewer_df = (sewer_df.withColumn('End_Date', sewer_df.End_Date.cast('timestamp'))\n                    .withColumn('Gallons', sewer_df.Gallons.cast('int'))\n                    .withColumn('Manhole', sewer_df.Manhole.cast('int'))\n                    )\n# print changes\nsewer_df.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Manhole: integer (nullable = true)\n-- Start_Date: timestamp (nullable = true)\n-- End_Date: timestamp (nullable = true)\n-- Location: string (nullable = true)\n-- Event: string (nullable = true)\n-- Rain: string (nullable = true)\n-- Gallons: integer (nullable = true)\n-- Lat: double (nullable = true)\n-- Long: double (nullable = true)\n\n&lt;IPython.core.display.Javascript object&gt;\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["# Let's find out what data is missing and how we can reason with that...\n# This is no go area for large data, use sql instead\nnan_value_features = {col: sewer_df.filter(F.isnull(sewer_df[col])).count() \\\n                                           for col in sewer_df.columns}\nprint(nan_value_features)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{&#39;Manhole&#39;: 6, &#39;Start_Date&#39;: 1, &#39;End_Date&#39;: 10, &#39;Location&#39;: 3, &#39;Event&#39;: 146, &#39;Rain&#39;: 608, &#39;Gallons&#39;: 23, &#39;Lat&#39;: 3, &#39;Long&#39;: 3}\n&lt;IPython.core.display.Javascript object&gt;\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["# get unique/cardinality values from each categorical feature\ncardinality_feat = {col: sewer_df.select(F.countDistinct(col)).collect()[0][0]\\\n                   for col,col_type in sewer_df.dtypes if col_type == 'string' }\n\nprint(cardinality_feat)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{&#39;Location&#39;: 164, &#39;Event&#39;: 48, &#39;Rain&#39;: 102}\n&lt;IPython.core.display.Javascript object&gt;\n</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["## Missing value report\n---\nIt is important to discuss the missing data with the stackholders or the data team<br>\nto understand the infomation convey by the missing data. \n\n- Lets take for example the Rain Feature with 608 missing data, what does that mean?\n> The was no rain that particular day, right?<br>\n> So this means we can't drop the rain feature instead we fill it with a reasonable value e.g **'No Rain'**\n\n- **Location, long and lat** on the other hand might need the stackholders/ data team to clearify<br>\nif the is some link/direction info between the pipes  which can help us infer the location, before any assumption.\n\n- **'Event'** most being **Precipitation** is rain, snow, sleet, or hail â€” any kind of weather condition where something's falling from the sky.<br>\n> This feature will make sense to be null/missing if the is also no rain, but not always.<br>\n> let's mark Nan as **clear sky** unless validated otherwise.\n\n### Lets investigate a bit more into these categorical features"],"metadata":{}},{"cell_type":"code","source":["sewer_df.select('Location','Event', 'Rain').distinct().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+----+\n            Location|               Event|Rain|\n+--------------------+--------------------+----+\nWinston-Thomas Ol...|       Leaking joint|null|\n       5900 S Rogers|                null|null|\nIndustrial lift s...|Power outage at l...|null|\n  Sherwood Oaks Park|                null|null|\nGrimes Lane - Mic...|       Precipitation|1.58|\n        Gifford Road|       Precipitation|1.23|\nCollege Mall - St...|       Precipitation|null|\nSW of cul-de-sac ...|Sewer main broken...|null|\nWalnut Creek Lift...|       Precipitation|1.79|\n        Micro Motors|                null|2.50|\n  Blucher Poole WWTP|                null|null|\n         Dunn meadow|Blockage in sewer...|null|\n   Indiana Warehouse|       Precipitation|null|\nGrimes Lane - Mic...|       Precipitation|2.95|\n1500 S Rogers - I...|Snow melt / preci...|1.20|\n        Gifford Road|       Precipitation|0.43|\nBrookdale &amp; Woodburn|Snow melt / preci...|4.38|\n2600 Block of N W...|Blockage in sewer...|null|\nCollege Mall - Bl...|       Precipitation|1.90|\n  Tower Lift Station|         Power surge|null|\n+--------------------+--------------------+----+\nonly showing top 20 rows\n\n&lt;IPython.core.display.Javascript object&gt;\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["## Missing values Assumptions Review\n\n - So **Rain** is the measure of rain in volume/litres not what we suspected. **We must extend the data dictionary**,<br>\n > now is better we can fill Null for Rain with a Zero meaning the was no Rain.<br>\n > Wait! This is not a hackathon Allie, we might need to pull weather data from google Earth to validate the assumptions.\n \n - **'Event' has 48** most being **Precipitation** but we can see that we have 48 unique values for Event e.g **Blockage, Sewer main blockage , power and more**<br>\n \n - **Location & Event** Seems to be compound features,<br> we need to do some deep dive mining and  see how we can explode them if possible\n \n - Cast **Rain** to float which in pyspark is *DoubleType or Just FloatType* following Java data-types\n \n #### more drill and wrangling is required here"],"metadata":{}}],"metadata":{"name":"001_Data_understanding_&_Wrangling","notebookId":2178687180318787},"nbformat":4,"nbformat_minor":0}
